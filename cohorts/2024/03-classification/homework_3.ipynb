{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7f165fc",
   "metadata": {},
   "source": [
    "# Homework #3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbc91ba",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e10879",
   "metadata": {},
   "source": [
    "In this homework, we will use Bank Marketing dataset. Download it from [here](https://archive.ics.uci.edu/static/public/222/bank+marketing.zip)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b801170a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mutual_info_score, accuracy_score, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bc70f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "392e58e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'bank+marketing/bank/bank-full.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbank+marketing/bank/bank-full.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m data\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1662\u001b[0m     f,\n\u001b[1;32m   1663\u001b[0m     mode,\n\u001b[1;32m   1664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1665\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1666\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1667\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1668\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1669\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1670\u001b[0m )\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'bank+marketing/bank/bank-full.csv'"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('bank+marketing/bank/bank-full.csv', delimiter=';')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9afaf70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f278e656",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def93194",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc979aa",
   "metadata": {},
   "source": [
    "For the rest of the homework, you'll need to use only these columns:\n",
    "\n",
    "* `age`,\n",
    "* `job`,\n",
    "* `marital`,\n",
    "* `education`,\n",
    "* `balance`,\n",
    "* `housing`,\n",
    "* `contact`,\n",
    "* `day`,\n",
    "* `month`,\n",
    "* `duration`,\n",
    "* `campaign`,\n",
    "* `pdays`,\n",
    "* `previous`,\n",
    "* `poutcome`,\n",
    "* `y`\n",
    "\n",
    "Select only them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cf4f54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features = [\n",
    "    'age', 'job', 'marital', 'education', 'balance', 'housing', 'contact', \n",
    "    'day', 'month', 'duration', 'campaign', 'pdays', 'previous', 'poutcome', 'y'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203b58d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = data[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea672c17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee382c0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2a5810",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca32631",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfa73b6",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74099f56",
   "metadata": {},
   "source": [
    "What is the most frequent observation (mode) for the column `education`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177af65f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.describe(include=[\"O\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd24972",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data['education'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d345600",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cfc5d6",
   "metadata": {},
   "source": [
    "* Create the correlation matrix for the numerical features of your dataset\n",
    "* In a correlation matrix, you compute the correlation coefficient between every pair of features in the dataset\n",
    "* What are the two features that have the biggest correlation in this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d266a309",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_numeric = data.copy()\n",
    "data_numeric = data.drop(\n",
    "    ['job', 'marital', 'education', 'housing', 'contact', 'month', 'poutcome', 'y'], axis=1\n",
    ")\n",
    "data_numeric.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c789d653",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_numeric.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39d4ab1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 6))\n",
    "sns.heatmap(data_numeric.corr(),annot=True,linewidths=.5, cmap=\"Blues\")\n",
    "plt.title('Heatmap showing correlations between numerical data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3752b5a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_numeric.corr().unstack().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76464e1",
   "metadata": {},
   "source": [
    "`pdays` and `previous`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b68b43",
   "metadata": {},
   "source": [
    "## Target encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60490dc",
   "metadata": {},
   "source": [
    "* Now we want to encode the `y` variable\n",
    "* Let's replace the values `yes`/`no` with `1`/`0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2a9d99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.y = (data.y == 'yes').astype(int)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a213a5c",
   "metadata": {},
   "source": [
    "## Split the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199bdbda",
   "metadata": {},
   "source": [
    "* Split your data in train/val/test sets with 60%/20%/20% distribution\n",
    "* Use Scikit-Learn for that (the `train_test_split` function) and set the seed to `42`\n",
    "* Make sure that the target value `y` is not in your dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf07feae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e641c553",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_full_train, df_test = train_test_split(data, test_size=0.2, random_state=SEED)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=SEED)\n",
    "\n",
    "assert len(data) == (len(df_train) + len(df_val) + len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adcc7d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(df_train), len(df_val), len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3416c2ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8073275",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train = df_train.y.values\n",
    "y_val = df_val.y.values\n",
    "y_test = df_test.y.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3c270f",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77812a2",
   "metadata": {},
   "source": [
    "* Calculate the mutual information score between `y` and other categorical variables in the dataset. Use the training set only\n",
    "* Round the scores to 2 decimals using `round(score, 2)`\n",
    "* Which of these variables has the biggest score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3b6ab2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_mi(series):\n",
    "    return mutual_info_score(series, df_train.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f1887a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = ['job', 'marital', 'education', 'housing', 'contact', 'month', 'poutcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d100616",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_mi = df_train[cat].apply(calculate_mi)\n",
    "df_mi = df_mi.sort_values(ascending=False).to_frame(name='MI')\n",
    "df_mi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067dc099",
   "metadata": {},
   "source": [
    "`poutcome` has the biggest score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab12289",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = df_train.drop('y', axis=1)\n",
    "df_val = df_val.drop('y', axis=1)\n",
    "df_test = df_test.drop('y', axis=1)\n",
    "\n",
    "assert 'y' not in df_train.columns\n",
    "assert 'y' not in df_val.columns\n",
    "assert 'y' not in df_test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe5bfa7",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cac43da",
   "metadata": {},
   "source": [
    "* Now let's train a logistic regression\n",
    "* Remember that we have several categorical variables in the dataset. Include them using one-hot encoding\n",
    "* Fit the model on the training dataset:\n",
    "    * To make sure the results are reproducible across different versions of Scikit-Learn, fit the model with these parameters:\n",
    "    * `model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)`\n",
    "* Calculate the accuracy on the validation dataset and round it to 2 decimal digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf5a1f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dv = DictVectorizer(sparse=False)\n",
    "train_dict = df_train.to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec786c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='liblinear', max_iter=1000, C=1.0, random_state=SEED)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0ae94c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_dict = df_val.to_dict(orient='records')\n",
    "X_val = dv.transform(val_dict)\n",
    "\n",
    "y_pred = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea66aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_score = accuracy_score(y_val, y_pred)\n",
    "original_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b0f9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_proba(X_val)[:, 1]\n",
    "term_decision = (y_pred >= 0.5)\n",
    "accuracy = (y_val == term_decision).mean()\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ed5589",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy = np.round(original_score, 2)\n",
    "print(f'Accuracy = {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fa18b1",
   "metadata": {},
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e247849e",
   "metadata": {},
   "source": [
    "* Let's find the least useful feature using the _feature elimination_ technique\n",
    "* Train a model with all these features (using the same parameters as in Q4)\n",
    "* Now exclude each feature from this set and train a model without it. Record the accuracy for each model\n",
    "* For each feature, calculate the difference between the original accuracy and the accuracy without the feature\n",
    "* Which of following feature has the smallest difference?\n",
    "    - `age`\n",
    "    - `balance`\n",
    "    - `marital`\n",
    "    - `previous`\n",
    "    \n",
    "> **note:** the difference doesn't have to be positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748a7867",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features = df_train.columns.to_list()\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabc785c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores = pd.DataFrame(columns=['eliminated_feature', 'accuracy', 'difference'])\n",
    "for feature in features:\n",
    "    subset = features.copy()\n",
    "    subset.remove(feature)\n",
    "    \n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    train_dict = df_train[subset].to_dict(orient='records')\n",
    "    X_train = dv.fit_transform(train_dict)\n",
    "\n",
    "    model = LogisticRegression(solver='liblinear', max_iter=1000, C=1.0, random_state=SEED)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    val_dict = df_val[subset].to_dict(orient='records')\n",
    "    X_val = dv.transform(val_dict)\n",
    "    \n",
    "    y_pred = model.predict(X_val)\n",
    "    score = accuracy_score(y_val, y_pred)\n",
    "    \n",
    "    scores.loc[len(scores)] = [feature, score, original_score - score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c253ea7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fddefae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores[scores.index == scores.difference.abs().idxmin()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c45b41",
   "metadata": {},
   "source": [
    "`age` and `balance` features are the least important in our case. So, you we can choose one of them.\n",
    "\n",
    "> **note:** you can get other answers in Google Colab. Therefore, we decided to mark all the answers as correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dede5e",
   "metadata": {},
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527539a6",
   "metadata": {},
   "source": [
    "* Now let's train a regularized logistic regression\n",
    "* Let's try the following values of the parameter `C`: `[0, 0.01, 0.1, 1, 10]`\n",
    "* Train models using all the features as in Q4\n",
    "* Calculate the accuracy on the validation dataset and round it to 3 decimal digits\n",
    "* Which of these `C` leads to the best accuracy on the validation set?\n",
    "> **note:** If there are multiple options, select the smallest `C`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee58b860",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bd46e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dv = DictVectorizer(sparse=False)\n",
    "train_dict = df_train.to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dict)\n",
    "\n",
    "val_dict = df_val.to_dict(orient='records')\n",
    "X_val = dv.transform(val_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcdf686",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores = {}\n",
    "for C in [0.01, 0.1, 1, 10, 100]:\n",
    "    model = LogisticRegression(solver='liblinear', max_iter=1000, C=C, random_state=SEED)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    score = accuracy_score(y_val, y_pred)\n",
    "    scores[C] = round(score, 3)\n",
    "    print(f'C = {C}:\\t Accuracy = {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaa5761",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cabb9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f'The smallest `C` is {max(scores, key=scores.get)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384f76f9",
   "metadata": {},
   "source": [
    "`C = 0.1` is also a valid answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a23b87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
